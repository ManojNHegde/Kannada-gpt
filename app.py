import gradio as gr
from backend.voice_input import get_kannada_voice_input
from qa_chain import ask_llama
from backend.translator import translate_en_to_kn
from backend.tts import speak_kannada

def process_audio(audio_file, chat_history):
    en_text, kn_text = get_kannada_voice_input(audio_file)

    if not en_text or not kn_text:
        chat_history.append({"role": "user", "content": "‚ö†Ô∏è ‡≤ß‡≥ç‡≤µ‡≤®‡≤ø‡≤Ø‡≤®‡≥ç‡≤®‡≥Å ‡≤ó‡≥Å‡≤∞‡≥Å‡≤§‡≤ø‡≤∏‡≤≤‡≤æ‡≤ó‡≤ø‡≤≤‡≥ç‡≤≤."})
        return chat_history, None

    llm_response_en = ask_llama(en_text)
    kn_response = translate_en_to_kn(llm_response_en)
    tts_audio_path = speak_kannada(kn_response)

    chat_history.append({"role": "user", "content": kn_text})
    chat_history.append({"role": "assistant", "content": kn_response})

    return chat_history, tts_audio_path

with gr.Blocks() as demo:
    gr.Markdown("## üó£Ô∏è ‡≤ï‡≤®‡≥ç‡≤®‡≤° ‡≤ß‡≥ç‡≤µ‡≤®‡≤ø ‡≤ö‡≤æ‡≤ü‡≥ç‚Äå‡≤¨‡≤æ‡≤ü‡≥ç")
    chatbot = gr.Chatbot(label="üí¨ ‡≤∏‡≤Ç‡≤≠‡≤æ‡≤∑‡≤£‡≥Ü", type="messages")
    audio_input = gr.Audio(sources=["microphone"], type="filepath", format="mp3", label="üé§ ‡≤ß‡≥ç‡≤µ‡≤®‡≤ø ‡≤®‡≤Æ‡≥Ç‡≤¶‡≤ø‡≤∏‡≤ø")
    output_audio = gr.Audio(label="üîä ‡≤∏‡≥ç‡≤™‡≥Ä‡≤ö‡≥ç ‡≤î‡≤ü‡≥ç‚Äå‡≤™‡≥Å‡≤ü‡≥ç")
    btn = gr.Button("üì§ ‡≤ï‡≤≥‡≥Å‡≤π‡≤ø‡≤∏‡≤ø")
    state = gr.State([])

    btn.click(fn=process_audio, inputs=[audio_input, state], outputs=[chatbot, output_audio])

demo.launch()
